{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Recommender Systems\n",
    "\n",
    "Recommender systems are among the most impactful applications of machine learning, driving a large fraction of sales and engagement on platforms like Netflix, Amazon, and others.\n",
    "\n",
    "## I. Collaborative Filtering\n",
    "\n",
    "This approach recommends items by identifying patterns in user ratings. The core idea is that users who agreed in the past (rated items similarly) will likely agree in the future.\n",
    "\n",
    "### Notation\n",
    "- $n_u$: number of users\n",
    "- $n_m$: number of movies (items)\n",
    "- $r(i, j)$: 1 if user $j$ has rated movie $i$, 0 otherwise.\n",
    "- $y^{(i, j)}$: The rating (e.g., 0-5 stars) given by user $j$ to movie $i$.\n",
    "- $\\vec{x}^{(i)}$: A feature vector describing movie $i$.\n",
    "- $\\vec{w}^{(j)}, b^{(j)}$: Parameters for user $j$.\n",
    "- $n$: number of features per movie.\n",
    "\n",
    "### The Algorithm: Learning Features and Parameters Simultaneously\n",
    "Initially, we can think of this as learning a separate linear regression model for each user, where the prediction for user $j$ on movie $i$ is $\\vec{w}^{(j)} \\cdot \\vec{x}^{(i)} + b^{(j)}$.\n",
    "\n",
    "However, the real power of collaborative filtering is that we often **don't have the movie features** $\\vec{x}^{(i)}$. The key insight is that the algorithm can **learn the features for the movies and the parameters for the users at the same time.**\n",
    "\n",
    "The overall cost function to minimize is:\n",
    "$$\n",
    "J(\\vec{x}^{(1)},...,\\vec{x}^{(n_m)}, \\vec{w}^{(1)},...,\\vec{w}^{(n_u)}, b^{(1)},...,b^{(n_u)}) = \\frac{1}{2} \\sum_{(i,j):r(i,j)=1} \\left( (\\vec{w}^{(j)} \\cdot \\vec{x}^{(i)} + b^{(j)}) - y^{(i,j)} \\right)^2 + \\frac{\\lambda}{2} \\sum_{j=1}^{n_u} \\sum_{k=1}^{n} (w_k^{(j)})^2 + \\frac{\\lambda}{2} \\sum_{i=1}^{n_m} \\sum_{k=1}^{n} (x_k^{(i)})^2\n",
    "$$\n",
    "\n",
    "This function aims to find:\n",
    "- **User parameters** ($\\vec{w}^{(j)}, b^{(j)}$) that describe what kind of movies a user likes.\n",
    "- **Movie features** ($\\vec{x}^{(i)}$) that describe the properties of a movie (e.g., how much romance or action it has).\n",
    "\n",
    "### Finding Related Items\n",
    "Once the movie feature vectors $\\vec{x}^{(i)}$ are learned, you can find movies similar to movie $i$ by finding movies $k$ where the squared distance $||\\vec{x}^{(i)} - \\vec{x}^{(k)}||^2$ is small.\n",
    "\n",
    "### Practical Implementation Details\n",
    "\n",
    "#### Mean Normalization\n",
    "This is a crucial preprocessing step that helps with the **cold start problem** (making reasonable predictions for new users who have rated nothing).\n",
    "1.  For each movie, calculate the average rating $\\mu_i$ across all users who have rated it.\n",
    "2.  Create a new, normalized ratings matrix by subtracting the mean rating from each existing rating: $y_{norm}^{(i,j)} = y^{(i,j)} - \\mu_i$.\n",
    "3.  Train the collaborative filtering algorithm using these normalized ratings.\n",
    "4.  When making a prediction for user $j$ on movie $i$, add the mean back: $\\text{prediction} = \\vec{w}^{(j)} \\cdot \\vec{x}^{(i)} + b^{(j)} + \\mu_i$.\n",
    "\n",
    "For a new user with no ratings, the learned parameters $\\vec{w}$ and $b$ will be zero (due to regularization), so their predicted rating for any movie will simply be the movie's average rating, which is a much more reasonable guess than zero.\n",
    "\n",
    "#### TensorFlow for Collaborative Filtering\n",
    "Because the collaborative filtering cost function doesn't fit the standard Keras `Sequential` model structure, we need a more fundamental way to perform gradient descent. TensorFlow's **`GradientTape`** is perfect for this. It allows for **automatic differentiation** (autodiff).\n",
    "1.  Define your parameters ($\\vec{w}, b, \\vec{x}$) as `tf.Variable`.\n",
    "2.  Write a function to calculate the cost $J$.\n",
    "3.  Inside a `with tf.GradientTape() as tape:` block, call your cost function. TensorFlow \"records\" all the operations.\n",
    "4.  Call `tape.gradient(J, [params])` to get the gradients of $J$ with respect to your parameters.\n",
    "5.  Use an optimizer (like `tf.keras.optimizers.Adam`) to apply these gradients to your parameters."
   ],
   "id": "79676aff27c24ade"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-02T14:33:45.235923Z",
     "start_time": "2025-08-02T14:33:45.227604Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Initialize a parameter 'w' as a TensorFlow variable\n",
    "w = tf.Variable(3.0)\n",
    "\n",
    "# Define the cost function J = (w*x - y)^2\n",
    "# For this simple example, let x=1 and y=1\n",
    "x_train = 1.0\n",
    "y_train = 1.0\n",
    "\n",
    "# Use the GradientTape context to \"record\" the operations\n",
    "with tf.GradientTape() as tape:\n",
    "    # Forward pass: calculate the cost\n",
    "    cost = (w * x_train - y_train)**2\n",
    "\n",
    "# Calculate the gradient of the cost with respect to 'w'\n",
    "# This is the automatic differentiation step\n",
    "grad = tape.gradient(cost, w)\n",
    "\n",
    "print(f\"Initial w: {w.numpy()}\")\n",
    "print(f\"Cost: {cost.numpy()}\")\n",
    "print(f\"Gradient of cost w.r.t w: {grad.numpy()}\")\n",
    "\n",
    "# We can then use this gradient in an optimizer\n",
    "# For example, a single step of gradient descent:\n",
    "learning_rate = 0.1\n",
    "w.assign_sub(learning_rate * grad) # w = w - alpha * grad\n",
    "print(f\"New w after one step of gradient descent: {w.numpy()}\")"
   ],
   "id": "a89c7edb18c04bd3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial w: 3.0\n",
      "Cost: 4.0\n",
      "Gradient of cost w.r.t w: 4.0\n",
      "New w after one step of gradient descent: 2.5999999046325684\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## II. Content-Based Filtering with Deep Learning\n",
    "\n",
    "This is a more modern and powerful approach that uses features about the users and items directly.\n",
    "\n",
    "| Collaborative Filtering                                     | Content-Based Filtering                                      |\n",
    "| :---------------------------------------------------------- | :----------------------------------------------------------- |\n",
    "| Recommends based on what similar users liked.               | Recommends based on features of users and items.             |\n",
    "| Learns item features from the ratings matrix.               | Requires explicit feature vectors for users and items as input. |\n",
    "| Suffers from the cold start problem.                        | Handles new items well, as long as they have features.         |\n",
    "\n",
    "### The Two-Network Architecture\n",
    "A deep learning model for content-based filtering typically uses two parallel neural networks:\n",
    "1.  **User Network**: Takes a user feature vector ($x_u$) as input and outputs a user embedding vector ($v_u$).\n",
    "2.  **Item Network**: Takes an item (movie) feature vector ($x_m$) as input and outputs an item embedding vector ($v_m$).\n",
    "\n",
    "The final prediction is the **dot product** of these two embedding vectors: $\\hat{y} = v_u \\cdot v_m$. The entire system is trained end-to-end to minimize a cost function (e.g., Mean Squared Error between the predicted and actual ratings).\n",
    "\n",
    "![Content-Based Filtering NN](https://i.imgur.com/gKzBfC0.png)"
   ],
   "id": "f40f90046b6ffd5d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-02T14:30:44.575038Z",
     "start_time": "2025-08-02T14:30:44.534371Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, Input, Concatenate, Dot\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "# --- Define the User Network ---\n",
    "# Assume user_features have 128 dimensions\n",
    "user_input = Input(shape=(128,), name=\"user_input\")\n",
    "user_nn = Dense(256, activation='relu')(user_input)\n",
    "user_nn = Dense(128, activation='relu')(user_nn)\n",
    "user_vector = Dense(32, activation='linear', name=\"user_vector\")(user_nn) # Output is a 32-dim vector\n",
    "\n",
    "# --- Define the Item (Movie) Network ---\n",
    "# Assume item_features have 64 dimensions\n",
    "item_input = Input(shape=(64,), name=\"item_input\")\n",
    "item_nn = Dense(256, activation='relu')(item_input)\n",
    "item_nn = Dense(128, activation='relu')(item_nn)\n",
    "item_vector = Dense(32, activation='linear', name=\"item_vector\")(item_nn) # Output must be same size as user_vector\n",
    "\n",
    "# --- Compute the Dot Product ---\n",
    "# The Dot layer takes the two vectors and computes their dot product\n",
    "dot_product = Dot(axes=1)([user_vector, item_vector])\n",
    "\n",
    "# --- Create the full model ---\n",
    "model = Model(inputs=[user_input, item_input], outputs=dot_product)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "              loss='mean_squared_error')\n",
    "\n",
    "print(\"Content-based model created successfully.\")\n",
    "model.summary()"
   ],
   "id": "b88a4b287f6b9117",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Content-based model created successfully.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1mModel: \"functional_1\"\u001B[0m\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_1\"</span>\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001B[1m \u001B[0m\u001B[1mLayer (type)       \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1mOutput Shape     \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1m   Param #\u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1mConnected to     \u001B[0m\u001B[1m \u001B[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ user_input          │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m128\u001B[0m)       │          \u001B[38;5;34m0\u001B[0m │ -                 │\n",
       "│ (\u001B[38;5;33mInputLayer\u001B[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ item_input          │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m64\u001B[0m)        │          \u001B[38;5;34m0\u001B[0m │ -                 │\n",
       "│ (\u001B[38;5;33mInputLayer\u001B[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_4 (\u001B[38;5;33mDense\u001B[0m)     │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m256\u001B[0m)       │     \u001B[38;5;34m33,024\u001B[0m │ user_input[\u001B[38;5;34m0\u001B[0m][\u001B[38;5;34m0\u001B[0m]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_6 (\u001B[38;5;33mDense\u001B[0m)     │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m256\u001B[0m)       │     \u001B[38;5;34m16,640\u001B[0m │ item_input[\u001B[38;5;34m0\u001B[0m][\u001B[38;5;34m0\u001B[0m]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_5 (\u001B[38;5;33mDense\u001B[0m)     │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m128\u001B[0m)       │     \u001B[38;5;34m32,896\u001B[0m │ dense_4[\u001B[38;5;34m0\u001B[0m][\u001B[38;5;34m0\u001B[0m]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_7 (\u001B[38;5;33mDense\u001B[0m)     │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m128\u001B[0m)       │     \u001B[38;5;34m32,896\u001B[0m │ dense_6[\u001B[38;5;34m0\u001B[0m][\u001B[38;5;34m0\u001B[0m]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ user_vector (\u001B[38;5;33mDense\u001B[0m) │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m32\u001B[0m)        │      \u001B[38;5;34m4,128\u001B[0m │ dense_5[\u001B[38;5;34m0\u001B[0m][\u001B[38;5;34m0\u001B[0m]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ item_vector (\u001B[38;5;33mDense\u001B[0m) │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m32\u001B[0m)        │      \u001B[38;5;34m4,128\u001B[0m │ dense_7[\u001B[38;5;34m0\u001B[0m][\u001B[38;5;34m0\u001B[0m]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dot_1 (\u001B[38;5;33mDot\u001B[0m)         │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m1\u001B[0m)         │          \u001B[38;5;34m0\u001B[0m │ user_vector[\u001B[38;5;34m0\u001B[0m][\u001B[38;5;34m0\u001B[0m… │\n",
       "│                     │                   │            │ item_vector[\u001B[38;5;34m0\u001B[0m][\u001B[38;5;34m0\u001B[0m] │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ user_input          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ item_input          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │     <span style=\"color: #00af00; text-decoration-color: #00af00\">33,024</span> │ user_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │     <span style=\"color: #00af00; text-decoration-color: #00af00\">16,640</span> │ item_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │     <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> │ dense_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │     <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> │ dense_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ user_vector (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">4,128</span> │ dense_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ item_vector (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">4,128</span> │ dense_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dot_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dot</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ user_vector[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│                     │                   │            │ item_vector[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Total params: \u001B[0m\u001B[38;5;34m123,712\u001B[0m (483.25 KB)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">123,712</span> (483.25 KB)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Trainable params: \u001B[0m\u001B[38;5;34m123,712\u001B[0m (483.25 KB)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">123,712</span> (483.25 KB)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Non-trainable params: \u001B[0m\u001B[38;5;34m0\u001B[0m (0.00 B)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "\n",
    "### Scaling to Millions of Items: Retrieval and Ranking\n",
    "For a massive catalog, predicting a rating for every item for a single user is computationally infeasible. Large-scale systems use a two-step process:\n",
    "\n",
    "1.  **Retrieval**: Quickly generate a large list of a few hundred plausible candidates from the millions of items. This step prioritizes speed and broad coverage. Examples:\n",
    "    - Find items similar to items the user recently interacted with.\n",
    "    - Find the top items in the user's favorite genres.\n",
    "2.  **Ranking**: Use the more complex (and slower) deep learning model to score and rank the smaller set of candidates generated by the retrieval step. The top items from this ranked list are then shown to the user.\n",
    "\n",
    "---\n",
    "## III. (Optional) Principal Component Analysis (PCA)\n",
    "\n",
    "PCA is an unsupervised learning algorithm used for **dimensionality reduction**, most often to visualize high-dimensional data.\n",
    "\n",
    "### The Core Idea\n",
    "PCA finds a new, lower-dimensional set of axes (called **principal components**) onto which the original data can be projected. These new axes are chosen to **maximize the variance** (the \"spread\") of the projected data, thereby retaining as much information as possible.\n",
    "\n",
    "- **PCA vs. Linear Regression**: They are not the same. Linear regression is a supervised algorithm that minimizes the vertical distance to predict a label $y$. PCA is an unsupervised algorithm that finds a new axis that minimizes the shortest orthogonal distance from the data points.\n"
   ],
   "id": "871a0119404ef27a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-02T14:31:03.336951Z",
     "start_time": "2025-08-02T14:31:00.934839Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# 1. Sample high-dimensional data (e.g., 5 features)\n",
    "X_original = np.random.rand(100, 5) * [10, 1, 50, 20, 5] # Create some scale difference\n",
    "\n",
    "# 2. Preprocess: Scale the data (important for PCA)\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X_original)\n",
    "\n",
    "# 3. Instantiate and fit PCA\n",
    "# We want to reduce from 5 dimensions to 2 for visualization\n",
    "pca = PCA(n_components=2)\n",
    "pca.fit(X_scaled)\n",
    "\n",
    "# 4. Check the explained variance ratio\n",
    "# This tells us how much information (variance) each principal component captures\n",
    "explained_variance = pca.explained_variance_ratio_\n",
    "print(f\"Explained variance by component 1: {explained_variance[0]:.4f}\")\n",
    "print(f\"Explained variance by component 2: {explained_variance[1]:.4f}\")\n",
    "print(f\"Total variance explained by 2 components: {np.sum(explained_variance):.4f}\")\n",
    "\n",
    "# 5. Transform the data to the new 2D space\n",
    "X_reduced = pca.transform(X_scaled)\n",
    "\n",
    "print(f\"\\nOriginal data shape: {X_original.shape}\")\n",
    "print(f\"Reduced data shape: {X_reduced.shape}\")\n",
    "\n",
    "# Now you could plot X_reduced on a 2D scatter plot\n",
    "# import matplotlib.pyplot as plt\n",
    "# plt.scatter(X_reduced[:, 0], X_reduced[:, 1])\n",
    "# plt.xlabel(\"Principal Component 1\")\n",
    "# plt.ylabel(\"Principal Component 2\")\n",
    "# plt.title(\"Data Reduced to 2D using PCA\")\n",
    "# plt.show()"
   ],
   "id": "c80007d8a1df581c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explained variance by component 1: 0.2378\n",
      "Explained variance by component 2: 0.2210\n",
      "Total variance explained by 2 components: 0.4587\n",
      "\n",
      "Original data shape: (100, 5)\n",
      "Reduced data shape: (100, 2)\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "c39ffc3146090483"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
